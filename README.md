# AI-Project-1
As an AI and data science project, this repository explores tools and techniques for improving online conversations and detecting toxic behaviors, with a focus on language models and sentiment analysis.

Milestones 1-3 cover the development of a Docker-based environment, a sentiment analysis app using Streamlit and pretrained models from the HuggingFace library, and a multi-headed toxicity classifier based on a pretrained language model.

Milestone 4 includes documentation of the code and results, as well as the creation of a landing page and a demo video.

The project aims to contribute to the creation of safer and more inclusive online spaces, where individuals can freely express their views and engage in productive discussions. 
